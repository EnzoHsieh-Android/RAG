#!/usr/bin/env python3
"""
æ¨è–¦ç³»çµ±ç²¾æº–åº¦æ¸¬è©¦è…³æœ¬
æ¸¬è©¦ä¸åŒé¡å‹çš„æŸ¥è©¢ä¸¦åˆ†ææ¨è–¦ç²¾æº–åº¦
"""

import requests
import json
import time
from typing import List, Dict, Tuple

# æ¸¬è©¦é…ç½®
API_BASE = "http://localhost:8081/api/v2/recommend"
TEST_QUERIES = [
    # ç§‘å¹»/ç§‘æŠ€é¡
    {
        "query": "æˆ‘æƒ³çœ‹ç§‘å¹»å°èªª", 
        "expected_tags": ["ç§‘å¹»", "å°èªª", "ç§‘æŠ€", "æœªä¾†"],
        "category": "ç§‘å¹»æ–‡å­¸"
    },
    {
        "query": "æ¨è–¦äººå·¥æ™ºæ…§ç›¸é—œçš„æ›¸",
        "expected_tags": ["äººå·¥æ™ºæ…§", "AI", "æ©Ÿå™¨å­¸ç¿’", "ç§‘æŠ€"],
        "category": "äººå·¥æ™ºæ…§"
    },
    {
        "query": "é‡å­è¨ˆç®—çš„æ›¸ç±",
        "expected_tags": ["é‡å­è¨ˆç®—", "ç‰©ç†", "è¨ˆç®—æ©Ÿç§‘å­¸", "ç§‘æŠ€"],
        "category": "é‡å­ç‰©ç†"
    },
    
    # æ­·å²/æ–‡å­¸é¡
    {
        "query": "æˆ‘æƒ³äº†è§£ä¸­åœ‹æ­·å²",
        "expected_tags": ["æ­·å²", "ä¸­åœ‹", "æ–‡åŒ–", "å¤ä»£"],
        "category": "ä¸­åœ‹æ­·å²"
    },
    {
        "query": "æ¨è–¦ç¶“å…¸æ–‡å­¸ä½œå“",
        "expected_tags": ["æ–‡å­¸", "ç¶“å…¸", "å°èªª", "åè‘—"],
        "category": "ç¶“å…¸æ–‡å­¸"
    },
    
    # å•†æ¥­/æŠ•è³‡é¡
    {
        "query": "è‚¡ç¥¨æŠ•è³‡ç†è²¡æ›¸ç±",
        "expected_tags": ["æŠ•è³‡", "è‚¡ç¥¨", "ç†è²¡", "é‡‘è", "ç¶“æ¿Ÿ"],
        "category": "æŠ•è³‡ç†è²¡"
    },
    {
        "query": "å‰µæ¥­å’Œå•†æ¥­ç®¡ç†",
        "expected_tags": ["å‰µæ¥­", "å•†æ¥­", "ç®¡ç†", "ä¼æ¥­"],
        "category": "å•†æ¥­ç®¡ç†"
    },
    
    # ç”Ÿæ´»/å¥åº·é¡
    {
        "query": "å¿ƒç†å­¸å’Œè‡ªæˆ‘æˆé•·",
        "expected_tags": ["å¿ƒç†å­¸", "è‡ªæˆ‘æˆé•·", "å¿ƒç†", "æˆé•·"],
        "category": "å¿ƒç†æˆé•·"
    },
    {
        "query": "æ–™ç†å’Œç¾é£Ÿç›¸é—œ",
        "expected_tags": ["æ–™ç†", "ç¾é£Ÿ", "çƒ¹é£ª", "é£Ÿè­œ"],
        "category": "ç¾é£Ÿæ–™ç†"
    },
    
    # è—è¡“/è¨­è¨ˆé¡
    {
        "query": "è¨­è¨ˆå’Œè—è¡“æ›¸ç±",
        "expected_tags": ["è¨­è¨ˆ", "è—è¡“", "ç¾è¡“", "å‰µä½œ"],
        "category": "è—è¡“è¨­è¨ˆ"
    }
]

def call_api(endpoint: str, query: str) -> Tuple[Dict, float, bool]:
    """èª¿ç”¨æ¨è–¦API"""
    try:
        start_time = time.time()
        response = requests.post(
            f"{API_BASE}/{endpoint}",
            json={"query": query},
            timeout=30
        )
        response_time = time.time() - start_time
        
        if response.status_code == 200:
            return response.json(), response_time, True
        else:
            return {"error": f"HTTP {response.status_code}"}, response_time, False
            
    except Exception as e:
        return {"error": str(e)}, 0, False

def calculate_tag_relevance(book_tags: List[str], expected_tags: List[str]) -> float:
    """è¨ˆç®—æ¨™ç±¤ç›¸é—œæ€§è©•åˆ†"""
    if not book_tags or not expected_tags:
        return 0.0
    
    # å°‡æ‰€æœ‰æ¨™ç±¤è½‰ç‚ºå°å¯«é€²è¡Œæ¯”è¼ƒ
    book_tags_lower = [tag.lower() for tag in book_tags]
    expected_tags_lower = [tag.lower() for tag in expected_tags]
    
    # è¨ˆç®—åŒ¹é…çš„æ¨™ç±¤æ•¸é‡
    matches = 0
    for expected in expected_tags_lower:
        for book_tag in book_tags_lower:
            if expected in book_tag or book_tag in expected:
                matches += 1
                break
    
    # ç›¸é—œæ€§è©•åˆ† = åŒ¹é…æ•¸é‡ / æœŸæœ›æ¨™ç±¤æ•¸é‡
    return matches / len(expected_tags_lower)

def analyze_recommendations(results: List[Dict], expected_tags: List[str]) -> Dict[str, float]:
    """åˆ†ææ¨è–¦çµæœ"""
    if not results:
        return {"avg_relevance": 0.0, "top1_relevance": 0.0, "top3_relevance": 0.0, "total_books": 0}
    
    relevance_scores = []
    for book in results:
        book_tags = book.get("tags", [])
        relevance = calculate_tag_relevance(book_tags, expected_tags)
        relevance_scores.append(relevance)
    
    avg_relevance = sum(relevance_scores) / len(relevance_scores)
    top1_relevance = relevance_scores[0] if relevance_scores else 0.0
    top3_relevance = sum(relevance_scores[:3]) / min(3, len(relevance_scores))
    
    return {
        "avg_relevance": avg_relevance,
        "top1_relevance": top1_relevance, 
        "top3_relevance": top3_relevance,
        "total_books": len(results)
    }

def run_accuracy_test():
    """åŸ·è¡Œç²¾æº–åº¦æ¸¬è©¦"""
    print("ğŸ¯ é–‹å§‹æ¨è–¦ç³»çµ±ç²¾æº–åº¦æ¸¬è©¦")
    print(f"ğŸ“Š æ¸¬è©¦æŸ¥è©¢æ•¸é‡: {len(TEST_QUERIES)}")
    print("=" * 80)
    
    natural_results = []
    fast_results = []
    
    for i, test_case in enumerate(TEST_QUERIES, 1):
        query = test_case["query"]
        expected_tags = test_case["expected_tags"]
        category = test_case["category"]
        
        print(f"\n{i}. æ¸¬è©¦æŸ¥è©¢: {query}")
        print(f"   é¡åˆ¥: {category}")
        print(f"   æœŸæœ›æ¨™ç±¤: {expected_tags}")
        
        # æ¸¬è©¦Natural API
        print("   ğŸ” æ¸¬è©¦Natural API...")
        natural_data, natural_time, natural_success = call_api("natural", query)
        
        # æ¸¬è©¦Fast API  
        print("   âš¡ æ¸¬è©¦Fast API...")
        fast_data, fast_time, fast_success = call_api("fast", query)
        
        if natural_success and fast_success:
            # å¾recommendation.resultsè·¯å¾‘ç²å–çµæœ
            natural_books = natural_data.get("recommendation", {}).get("results", [])
            fast_books = fast_data.get("recommendation", {}).get("results", [])
            
            # åˆ†ææ¨è–¦ç²¾æº–åº¦
            natural_analysis = analyze_recommendations(natural_books, expected_tags)
            fast_analysis = analyze_recommendations(fast_books, expected_tags)
            
            print(f"   ğŸ“Š Naturalçµæœ: {natural_analysis['total_books']}æœ¬æ›¸, Top1ç›¸é—œæ€§: {natural_analysis['top1_relevance']:.2f}, å¹³å‡: {natural_analysis['avg_relevance']:.2f}, è€—æ™‚: {natural_time:.2f}s")
            print(f"   ğŸ“Š Fastçµæœ: {fast_analysis['total_books']}æœ¬æ›¸, Top1ç›¸é—œæ€§: {fast_analysis['top1_relevance']:.2f}, å¹³å‡: {fast_analysis['avg_relevance']:.2f}, è€—æ™‚: {fast_time:.2f}s")
            
            # é¡¯ç¤ºTop3æ¨è–¦æ›¸ç±
            print("   ğŸ“š Natural API Top 3:")
            for j, book in enumerate(natural_books[:3], 1):
                relevance = calculate_tag_relevance(book.get("tags", []), expected_tags)
                print(f"      {j}. {book.get('title', 'Unknown')} - {book.get('author', 'Unknown')} (ç›¸é—œæ€§: {relevance:.2f})")
                print(f"         æ¨™ç±¤: {book.get('tags', [])}")
            
            natural_results.append({
                "query": query,
                "category": category, 
                "success": True,
                "analysis": natural_analysis,
                "time": natural_time
            })
            
            fast_results.append({
                "query": query,
                "category": category,
                "success": True, 
                "analysis": fast_analysis,
                "time": fast_time
            })
            
        else:
            print(f"   âŒ APIèª¿ç”¨å¤±æ•— - Natural: {natural_success}, Fast: {fast_success}")
            natural_results.append({"query": query, "category": category, "success": False})
            fast_results.append({"query": query, "category": category, "success": False})
        
        print("-" * 80)
    
    # çµ±è¨ˆç¸½é«”çµæœ
    print("\nğŸ“ˆ ç¸½é«”æ¸¬è©¦çµæœçµ±è¨ˆ:")
    print("=" * 80)
    
    successful_natural = [r for r in natural_results if r["success"]]
    successful_fast = [r for r in fast_results if r["success"]]
    
    if successful_natural:
        natural_avg_relevance = sum(r["analysis"]["avg_relevance"] for r in successful_natural) / len(successful_natural)
        natural_avg_top1 = sum(r["analysis"]["top1_relevance"] for r in successful_natural) / len(successful_natural)
        natural_avg_time = sum(r["time"] for r in successful_natural) / len(successful_natural)
        
        print(f"ğŸ” Natural API å¹³å‡è¡¨ç¾:")
        print(f"   æˆåŠŸç‡: {len(successful_natural)}/{len(TEST_QUERIES)} ({len(successful_natural)/len(TEST_QUERIES)*100:.1f}%)")
        print(f"   å¹³å‡ç›¸é—œæ€§: {natural_avg_relevance:.3f}")
        print(f"   Top1å¹³å‡ç›¸é—œæ€§: {natural_avg_top1:.3f}")
        print(f"   å¹³å‡éŸ¿æ‡‰æ™‚é–“: {natural_avg_time:.2f}s")
    
    if successful_fast:
        fast_avg_relevance = sum(r["analysis"]["avg_relevance"] for r in successful_fast) / len(successful_fast)
        fast_avg_top1 = sum(r["analysis"]["top1_relevance"] for r in successful_fast) / len(successful_fast)  
        fast_avg_time = sum(r["time"] for r in successful_fast) / len(successful_fast)
        
        print(f"\nâš¡ Fast API å¹³å‡è¡¨ç¾:")
        print(f"   æˆåŠŸç‡: {len(successful_fast)}/{len(TEST_QUERIES)} ({len(successful_fast)/len(TEST_QUERIES)*100:.1f}%)")
        print(f"   å¹³å‡ç›¸é—œæ€§: {fast_avg_relevance:.3f}")
        print(f"   Top1å¹³å‡ç›¸é—œæ€§: {fast_avg_top1:.3f}")
        print(f"   å¹³å‡éŸ¿æ‡‰æ™‚é–“: {fast_avg_time:.2f}s")
    
    # ä¿å­˜è©³ç´°çµæœ
    results_summary = {
        "test_time": time.strftime("%Y-%m-%d %H:%M:%S"),
        "total_queries": len(TEST_QUERIES),
        "natural_api": {
            "success_rate": len(successful_natural) / len(TEST_QUERIES),
            "avg_relevance": natural_avg_relevance if successful_natural else 0,
            "avg_top1_relevance": natural_avg_top1 if successful_natural else 0,
            "avg_response_time": natural_avg_time if successful_natural else 0
        },
        "fast_api": {
            "success_rate": len(successful_fast) / len(TEST_QUERIES),
            "avg_relevance": fast_avg_relevance if successful_fast else 0,
            "avg_top1_relevance": fast_avg_top1 if successful_fast else 0,
            "avg_response_time": fast_avg_time if successful_fast else 0
        },
        "detailed_results": {
            "natural": natural_results,
            "fast": fast_results
        }
    }
    
    with open("recommendation_accuracy_test.json", "w", encoding="utf-8") as f:
        json.dump(results_summary, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ“„ è©³ç´°æ¸¬è©¦çµæœå·²ä¿å­˜åˆ°: recommendation_accuracy_test.json")
    print("ğŸ¯ ç²¾æº–åº¦æ¸¬è©¦å®Œæˆ!")

if __name__ == "__main__":
    run_accuracy_test()